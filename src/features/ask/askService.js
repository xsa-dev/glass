const { BrowserWindow } = require('electron');
const { createStreamingLLM } = require('../common/ai/factory');
const { getCurrentModelInfo, windowPool, captureScreenshot } = require('../../window/windowManager');
const sessionRepository = require('../common/repositories/session');
const askRepository = require('./repositories');
const { getSystemPrompt } = require('../common/prompts/promptBuilder');

/**
 * @class AskService
 * @description ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  AI ëª¨ë¸ê³¼ í†µì‹ í•˜ì—¬ ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ëª¨ë“  ë¡œì§ì„ ìº¡ìŠí™”í•©ë‹ˆë‹¤.
 */
class AskService {
    /**
     * AskServiceì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
     */
    constructor() {
        console.log('[AskService] Service instance created.');
    }

    /**
     * ëŒ€í™” ê¸°ë¡ ë°°ì—´ì„ í”„ë¡¬í”„íŠ¸ì— ì í•©í•œ ë‹¨ì¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
     * @param {string[]} conversationTexts - ëŒ€í™” ë‚´ìš© ë¬¸ìì—´ì˜ ë°°ì—´
     * @returns {string} í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ë  í˜•ì‹ì˜ ëŒ€í™” ê¸°ë¡
     * @private
     */
    _formatConversationForPrompt(conversationTexts) {
        if (!conversationTexts || conversationTexts.length === 0) {
            return 'No conversation history available.';
        }
        // ìµœê·¼ 30ê°œì˜ ëŒ€í™”ë§Œ ì‚¬ìš©
        return conversationTexts.slice(-30).join('\n');
    }

    /**
     * ì‚¬ìš©ìì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ AI ëª¨ë¸ì— ì „ì†¡í•˜ê³ , ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
     * @param {string} userPrompt - ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ ë˜ëŠ” ë©”ì‹œì§€
     * @returns {Promise<{success: boolean, response?: string, error?: string}>} ì²˜ë¦¬ ê²°ê³¼ ê°ì²´
     */
    async sendMessage(userPrompt, conversationHistoryRaw=[]) {
        if (!userPrompt || userPrompt.trim().length === 0) {
            console.warn('[AskService] Cannot process empty message');
            return { success: false, error: 'Empty message' };
        }

        let sessionId;

        try {
            console.log(`[AskService] ğŸ¤– Processing message: ${userPrompt.substring(0, 50)}...`);

            // --- ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ---
            sessionId = await sessionRepository.getOrCreateActive('ask');
            await askRepository.addAiMessage({ sessionId, role: 'user', content: userPrompt.trim() });
            console.log(`[AskService] DB: Saved user prompt to session ${sessionId}`);
            
            const modelInfo = await getCurrentModelInfo(null, { type: 'llm' });
            if (!modelInfo || !modelInfo.apiKey) {
                throw new Error('AI model or API key not configured.');
            }
            console.log(`[AskService] Using model: ${modelInfo.model} for provider: ${modelInfo.provider}`);

            const screenshotResult = await captureScreenshot({ quality: 'medium' });
            const screenshotBase64 = screenshotResult.success ? screenshotResult.base64 : null;

            // const conversationHistoryRaw = this._getConversationHistory();
            const conversationHistory = this._formatConversationForPrompt(conversationHistoryRaw);

            const systemPrompt = getSystemPrompt('pickle_glass_analysis', conversationHistory, false);

            const messages = [
                { role: 'system', content: systemPrompt },
                {
                    role: 'user',
                    content: [
                        { type: 'text', text: `User Request: ${userPrompt.trim()}` },
                    ],
                },
            ];

            if (screenshotBase64) {
                messages[1].content.push({
                    type: 'image_url',
                    image_url: { url: `data:image/jpeg;base64,${screenshotBase64}` },
                });
            }
            
            const streamingLLM = createStreamingLLM(modelInfo.provider, {
                apiKey: modelInfo.apiKey,
                model: modelInfo.model,
                temperature: 0.7,
                maxTokens: 2048,
                usePortkey: modelInfo.provider === 'openai-glass',
                portkeyVirtualKey: modelInfo.provider === 'openai-glass' ? modelInfo.apiKey : undefined,
            });

            const response = await streamingLLM.streamChat(messages);
            const askWin = windowPool.get('ask');

            if (!askWin || askWin.isDestroyed()) {
                console.error("[AskService] Ask window is not available to send stream to.");
                response.body.getReader().cancel();
                return { success: false, error: 'Ask window is not available.' };
            }

            // --- ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ---
            await this._processStream(response.body, askWin, sessionId);

            // _processStream ë‚´ë¶€ì—ì„œ ì „ì²´ ì‘ë‹µì´ ì™„ë£Œë˜ë©´ ë°˜í™˜ë©ë‹ˆë‹¤.
            // í•˜ì§€ë§Œ ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¼ì˜ íŠ¹ì„±ìƒ ì´ ì§€ì ì—ì„œëŠ” ì§ì ‘ ë°˜í™˜ ê°’ì„ ì•Œê¸° ì–´ë µìŠµë‹ˆë‹¤.
            // ì„±ê³µ/ì‹¤íŒ¨ ì—¬ë¶€ëŠ” ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ë¡œì§ ë‚´ì—ì„œ ê²°ì •ë©ë‹ˆë‹¤.

        } catch (error) {
            console.error('[AskService] Error processing message:', error);
            const askWin = windowPool.get('ask');
            if (askWin && !askWin.isDestroyed()) {
                askWin.webContents.send('ask-response-stream-error', { error: error.message });
            }
            return { success: false, error: error.message };
        }
    }

    /**
     * AI ëª¨ë¸ë¡œë¶€í„° ë°›ì€ ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
     * @param {ReadableStream} body - ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì˜ body
     * @param {BrowserWindow} askWin - ì‘ë‹µì„ ë³´ë‚¼ ëŒ€ìƒ ì°½
     * @param {number} sessionId - í˜„ì¬ ì„¸ì…˜ ID
     * @returns {Promise<void>}
     * @private
     */
    async _processStream(body, askWin, sessionId) {
        const reader = body.getReader();
        const decoder = new TextDecoder();
        let fullResponse = '';
        let finalResult = { success: false }; // ìµœì¢… ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë³€ìˆ˜

        try {
            while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                const chunk = decoder.decode(value);
                const lines = chunk.split('\n').filter(line => line.trim() !== '');

                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const data = line.substring(6);
                        if (data === '[DONE]') {
                            askWin.webContents.send('ask-response-stream-end');
                            
                            await askRepository.addAiMessage({ sessionId, role: 'assistant', content: fullResponse });
                            console.log(`[AskService] DB: Saved assistant response to session ${sessionId}`);
                            
                            // ìŠ¤íŠ¸ë¦¼ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ, ìµœì¢… ê²°ê³¼ë¥¼ ì„±ê³µìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
                            // ì‹¤ì œ ë°˜í™˜ì€ sendMessageì—ì„œ ì´ë£¨ì–´ì§€ì§€ë§Œ, ë¡œì§ìƒì˜ ì™„ë£Œë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
                            return; 
                        }
                        try {
                            const json = JSON.parse(data);
                            const token = json.choices[0]?.delta?.content || '';
                            if (token) {
                                fullResponse += token;
                                askWin.webContents.send('ask-response-chunk', { token });
                            }
                        } catch (error) {
                            // JSON íŒŒì‹± ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                        }
                    }
                }
            }
        } catch (streamError) {
            console.error('[AskService] Error while processing stream:', streamError);
            askWin.webContents.send('ask-response-stream-error', { error: streamError.message });
            // ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŒì„ ê¸°ë¡
        } finally {
            // ìŠ¤íŠ¸ë¦¼ì´ ì •ìƒì ìœ¼ë¡œ [DONE]ì„ ë°›ì§€ ëª»í•˜ê³  ì¢…ë£Œëœ ê²½ìš°ì—ë„
            // í˜„ì¬ê¹Œì§€ì˜ ì‘ë‹µì´ë¼ë„ ì €ì¥ ì‹œë„
            if (fullResponse) {
                 try {
                    await askRepository.addAiMessage({ sessionId, role: 'assistant', content: fullResponse });
                    console.log(`[AskService] DB: Saved partial assistant response to session ${sessionId} after stream interruption.`);
                } catch(dbError) {
                    console.error("[AskService] DB: Failed to save assistant response after stream interruption:", dbError);
                }
            }
        }
    }
}

// AskService í´ë˜ìŠ¤ì˜ ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ì—¬ ë‚´ë³´ëƒ…ë‹ˆë‹¤.
// ì´ë ‡ê²Œ í•˜ë©´ ì• í”Œë¦¬ì¼€ì´ì…˜ ì „ì²´ì—ì„œ ë™ì¼í•œ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê³µìœ í•˜ê²Œ ë©ë‹ˆë‹¤.
const askService = new AskService();

module.exports = askService;